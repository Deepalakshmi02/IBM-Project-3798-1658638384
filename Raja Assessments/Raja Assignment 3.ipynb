{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: RAJA.E\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HYVV_pc1hpxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team ID:PNT2022TMID03716\n"
      ],
      "metadata": {
        "id": "pu2iP43Ph48g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplimport numpy as np\n",
        "otlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8VHRclu8fn6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "nE3hEFHUfyiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",input_shape=(180, 180, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "OlGJUE2df6TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_set = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"flowers\",\n",
        "  validation_split=0.25,\n",
        "  subset=\"training\",\n",
        "  seed=132,\n",
        "  image_size=(180, 180),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "qFtwCDqxf-Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_set = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"flowers\",\n",
        "  validation_split=0.25,\n",
        "  subset=\"validation\",\n",
        "  seed=132,\n",
        "  image_size=(180, 180),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VfAeCMVxf-Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data_set.class_names"
      ],
      "metadata": {
        "id": "BITxoULAf-DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in train_data_set.take(1):\n",
        "  for i in range(6):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])"
      ],
      "metadata": {
        "id": "LkOSIElJf9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "x4yju0QHgeFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_normalized = train_data_set.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(dataset_normalized))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "Sobw-D2kgfvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n",
        "  # adding convolutional layer\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  # adding maxpooling layer\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  # adding flatten\n",
        "  layers.Flatten(),\n",
        "  # adding dense hidden layer\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  # adding dense output layer\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "fs7yN80vgfjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling model with categorical cross entropy and adam optimizer\n",
        "model.compile(optimizer='adam',\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "o1DZrWGNgfZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data_set,validation_data=val_data_set,epochs=epochs)\n"
      ],
      "metadata": {
        "id": "G0sixaLQgfNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kgJjcWbgsqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
        "plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSKDlXNBgsoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"CNN Model for Classification Of Flowers.h5\")"
      ],
      "metadata": {
        "id": "3K27CxCjgshx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('CNN Model for Classification Of Flowers.h5')"
      ],
      "metadata": {
        "id": "OJBi_HHegsRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(180, 180)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(class_names[np.argmax(score)],100 * np.max(score))"
      ],
      "metadata": {
        "id": "nV6fOysHg7sl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}